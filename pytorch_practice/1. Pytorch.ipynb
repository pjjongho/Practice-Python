{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4009e+01, 1.6171e-42],\n",
      "        [0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(4,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0952, 0.7677],\n",
      "        [0.4274, 0.2729],\n",
      "        [0.8436, 0.8098],\n",
      "        [0.7953, 0.7689]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(4,2, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0000, 2.3000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([3,2.3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(2,4, dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6955, 0.8201, 0.9861, 0.8973],\n",
      "        [0.2380, 0.7532, 0.4244, 0.2597]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "ft = torch.FloatTensor([1,2,3])\n",
    "print(ft)\n",
    "print(ft.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int16)\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.short())\n",
    "print(ft.int())\n",
    "print(ft.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "torch.int32\n"
     ]
    }
   ],
   "source": [
    "it = torch.IntTensor([1,2,3])\n",
    "print(it)\n",
    "print(it.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], dtype=torch.float64)\n",
      "tensor([1., 2., 3.], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(it.float())\n",
    "print(it.double())\n",
    "print(it.half())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6960])\n",
      "1.6959571838378906\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='cuda:0')\n",
      "tensor([1.6960], device='cuda:0')\n",
      "tensor([2.6960], device='cuda:0')\n",
      "tensor([2.6960], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y = torch.ones_like(x, device=device)\n",
    "print(y)\n",
    "\n",
    "x = x.to(device)\n",
    "print(x)\n",
    "z = x+y\n",
    "print(z)\n",
    "print(z.to('cpu', torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "t0 = torch.tensor(0)\n",
    "print(t0.ndim)\n",
    "print(t0.shape)\n",
    "print(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([3])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1,2,3])\n",
    "print(t1.ndim)\n",
    "print(t1.shape)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([3, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([[1,2,3],\n",
    "                   [4,5,6],\n",
    "                   [7,8,9]])\n",
    "\n",
    "print(t2.ndim)\n",
    "print(t2.shape)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([3, 3, 3])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.tensor([[[1,2,3],\n",
    "                   [4,5,6],\n",
    "                   [7,8,9]],\n",
    "                   [[1,2,3],\n",
    "                   [4,5,6],\n",
    "                   [7,8,9]],\n",
    "                   [[1,2,3],\n",
    "                   [4,5,6],\n",
    "                   [7,8,9]]])\n",
    "\n",
    "print(t3.ndim)\n",
    "print(t3.shape)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9701,  0.3007]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1,2)*2-1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9701, 0.3007]])\n",
      "tensor([[-0., 1.]])\n",
      "tensor([[-1.,  0.]])\n",
      "tensor([[-0.5000,  0.3007]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.abs(a)) # 절대값\n",
    "print(torch.ceil(a)) \n",
    "print(torch.floor(a))\n",
    "print(torch.clamp(a, -0.5, 0.5)) # a의 값을 -0.5 ~ 0.5 사이로 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9701,  0.3007]])\n",
      "tensor(-0.9701)\n",
      "tensor(0.3007)\n",
      "tensor(-0.3347)\n",
      "tensor(0.8986)\n",
      "tensor(-0.2917)\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(torch.min(a))\n",
    "print(torch.max(a))\n",
    "print(torch.mean(a))\n",
    "print(torch.std(a))\n",
    "print(torch.prod(a))\n",
    "print(torch.unique(torch.tensor([1,2,3,1,2,2]))) # 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7625, 0.0231],\n",
      "        [0.0139, 0.0602]])\n",
      "torch.return_types.max(\n",
      "values=tensor([0.7625, 0.0602]),\n",
      "indices=tensor([0, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.7625, 0.0602]),\n",
      "indices=tensor([0, 1]))\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2)\n",
    "print(x)\n",
    "print(x.max(dim=0))\n",
    "print(x.max(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.min(\n",
      "values=tensor([0.0139, 0.0231]),\n",
      "indices=tensor([1, 0]))\n",
      "torch.return_types.min(\n",
      "values=tensor([0.0231, 0.0139]),\n",
      "indices=tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "print(x.min(dim=0))\n",
    "print(x.min(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0821, 0.1670],\n",
      "        [0.3429, 0.3882]])\n",
      "tensor([[0.0559, 0.3859],\n",
      "        [0.4405, 0.3596]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(2,2)\n",
    "print(x)\n",
    "y=torch.rand(2,2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1380, 0.5529],\n",
      "        [0.7834, 0.7478]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1380, 0.5529],\n",
      "        [0.7834, 0.7478]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjong\\AppData\\Local\\Temp\\ipykernel_26716\\2982148854.py:2: UserWarning: An output with one or more elements was resized since it had shape [2, 4], which does not match the required output shape [2, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:35.)\n",
      "  torch.add(x,y, out=result)\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(2,4)\n",
    "torch.add(x,y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0821, 0.1670],\n",
      "        [0.3429, 0.3882]])\n",
      "tensor([[0.0559, 0.3859],\n",
      "        [0.4405, 0.3596]])\n",
      "tensor([[0.1380, 0.5529],\n",
      "        [0.7834, 0.7478]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0821, 0.1670],\n",
      "        [0.3429, 0.3882]])\n",
      "tensor([[0.1380, 0.5529],\n",
      "        [0.7834, 0.7478]])\n",
      "tensor([[-0.0559, -0.3859],\n",
      "        [-0.4405, -0.3596]])\n",
      "tensor([[-0.0559, -0.3859],\n",
      "        [-0.4405, -0.3596]])\n",
      "tensor([[-0.0559, -0.3859],\n",
      "        [-0.4405, -0.3596]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(x-y)\n",
    "print(torch.sub(x,y))\n",
    "print(x.sub(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0821, 0.1670],\n",
      "        [0.3429, 0.3882]])\n",
      "tensor([[0.1380, 0.5529],\n",
      "        [0.7834, 0.7478]])\n",
      "tensor([[0.0113, 0.0924],\n",
      "        [0.2686, 0.2903]])\n",
      "tensor([[0.0113, 0.0924],\n",
      "        [0.2686, 0.2903]])\n",
      "tensor([[0.0113, 0.0924],\n",
      "        [0.2686, 0.2903]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(x*y)\n",
    "print(torch.mul(x,y))\n",
    "print(x.mul(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0821, 0.1670],\n",
      "        [0.3429, 0.3882]])\n",
      "tensor([[0.1380, 0.5529],\n",
      "        [0.7834, 0.7478]])\n",
      "tensor([[0.5950, 0.3021],\n",
      "        [0.4377, 0.5191]])\n",
      "tensor([[0.5950, 0.3021],\n",
      "        [0.4377, 0.5191]])\n",
      "tensor([[0.5950, 0.3021],\n",
      "        [0.4377, 0.5191]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(x/y)\n",
    "print(torch.div(x,y))\n",
    "print(x.div(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0821, 0.1670],\n",
      "        [0.3429, 0.3882]])\n",
      "tensor([[0.1380, 0.5529],\n",
      "        [0.7834, 0.7478]])\n",
      "tensor([[0.1422, 0.1703],\n",
      "        [0.3514, 0.4799]])\n",
      "torch.return_types.svd(\n",
      "U=tensor([[-0.3491, -0.9371],\n",
      "        [-0.9371,  0.3491]]),\n",
      "S=tensor([0.6347, 0.0132]),\n",
      "V=tensor([[-0.5971, -0.8022],\n",
      "        [-0.8022,  0.5971]]))\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "z= torch.matmul(x,y)\n",
    "print(z)\n",
    "print(torch.svd(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(1.)\n",
      "tensor(2.)\n",
      "tensor(3.)\n",
      "tensor(4.)\n",
      "tensor([1., 3.])\n",
      "tensor([2., 4.])\n",
      "tensor([1., 2.])\n",
      "tensor([3., 4.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2],\n",
    "                  [3,4]])\n",
    "print(x)\n",
    "print(x[0,0])\n",
    "print(x[0,1])\n",
    "print(x[1,0])\n",
    "print(x[1,1])\n",
    "\n",
    "print(x[:, 0])\n",
    "print(x[:, 1])\n",
    "\n",
    "print(x[0, :])\n",
    "print(x[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3552,  0.1114,  0.3342,  0.9763,  0.5557],\n",
      "        [-0.0753,  1.0312,  2.0856, -0.9275,  0.3215],\n",
      "        [-0.1255, -1.4509,  0.1290,  0.9154,  0.1713],\n",
      "        [-0.4012,  0.8189, -0.2313,  0.9402,  1.3190]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3552,  0.1114,  0.3342,  0.9763,  0.5557, -0.0753,  1.0312,  2.0856,\n",
      "        -0.9275,  0.3215, -0.1255, -1.4509,  0.1290,  0.9154,  0.1713, -0.4012,\n",
      "         0.8189, -0.2313,  0.9402,  1.3190])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(20)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3552,  0.1114,  0.3342,  0.9763],\n",
      "        [ 0.5557, -0.0753,  1.0312,  2.0856],\n",
      "        [-0.9275,  0.3215, -0.1255, -1.4509],\n",
      "        [ 0.1290,  0.9154,  0.1713, -0.4012],\n",
      "        [ 0.8189, -0.2313,  0.9402,  1.3190]])\n"
     ]
    }
   ],
   "source": [
    "z = x.view(5, -1) # -1 : 나머지는 알아서 하라는 의미미\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2903])\n",
      "0.2902970314025879\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8806, 0.1016, 0.9165],\n",
      "         [0.9259, 0.8961, 0.3909],\n",
      "         [0.7515, 0.4127, 0.8357]]])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(1,3,3)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8806, 0.1016, 0.9165],\n",
      "        [0.9259, 0.8961, 0.3909],\n",
      "        [0.7515, 0.4127, 0.8357]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "t = tensor.squeeze()\n",
    "print(t)\n",
    "print(t.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9601, 0.5895, 0.5037],\n",
      "        [0.0861, 0.3489, 0.6524],\n",
      "        [0.7424, 0.2956, 0.8297]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(3,3)\n",
    "print(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9601, 0.5895, 0.5037],\n",
      "         [0.0861, 0.3489, 0.6524],\n",
      "         [0.7424, 0.2956, 0.8297]]])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = t.unsqueeze(dim=0) # 첫번째 차원(dim=0)을 기준으로 차원을 늘림\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9601],\n",
      "         [0.5895],\n",
      "         [0.5037]],\n",
      "\n",
      "        [[0.0861],\n",
      "         [0.3489],\n",
      "         [0.6524]],\n",
      "\n",
      "        [[0.7424],\n",
      "         [0.2956],\n",
      "         [0.8297]]])\n",
      "torch.Size([3, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor = t.unsqueeze(dim=2) # 세번째 차원(dim=2)을 기준으로 차원을 늘림\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 4.])\n",
      "tensor([2., 5.])\n",
      "tensor([3., 6.])\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([1,4])\n",
    "print(x)\n",
    "y = torch.FloatTensor([2,5])\n",
    "print(y)\n",
    "z = torch.FloatTensor([3,6])\n",
    "print(z)\n",
    "\n",
    "print(torch.stack([x,y,z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3327, -0.5516,  0.4599],\n",
      "         [ 0.3180, -1.6556,  1.2033],\n",
      "         [-0.4707, -0.6726, -0.5905]]])\n",
      "tensor([[[-0.4050, -0.0956,  0.0775],\n",
      "         [ 0.1231,  0.8187, -0.1040],\n",
      "         [ 1.2102,  0.5528, -0.5515]]])\n",
      "tensor([[[-0.3327, -0.5516,  0.4599],\n",
      "         [ 0.3180, -1.6556,  1.2033],\n",
      "         [-0.4707, -0.6726, -0.5905]],\n",
      "\n",
      "        [[-0.4050, -0.0956,  0.0775],\n",
      "         [ 0.1231,  0.8187, -0.1040],\n",
      "         [ 1.2102,  0.5528, -0.5515]]])\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,3)\n",
    "print(a)\n",
    "b=torch.randn(1,3,3)\n",
    "print(b)\n",
    "c=torch.cat((a,b), dim=0)\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3327, -0.5516,  0.4599],\n",
      "         [ 0.3180, -1.6556,  1.2033],\n",
      "         [-0.4707, -0.6726, -0.5905],\n",
      "         [-0.4050, -0.0956,  0.0775],\n",
      "         [ 0.1231,  0.8187, -0.1040],\n",
      "         [ 1.2102,  0.5528, -0.5515]]])\n",
      "torch.Size([1, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "c=torch.cat((a,b), dim=1)\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3327, -0.5516,  0.4599, -0.4050, -0.0956,  0.0775],\n",
      "         [ 0.3180, -1.6556,  1.2033,  0.1231,  0.8187, -0.1040],\n",
      "         [-0.4707, -0.6726, -0.5905,  1.2102,  0.5528, -0.5515]]])\n",
      "torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "c=torch.cat((a,b), dim=2)\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9791, 0.4741, 0.6473, 0.5294, 0.7285, 0.8763],\n",
      "        [0.3318, 0.1018, 0.4189, 0.2183, 0.9732, 0.5814],\n",
      "        [0.3475, 0.8663, 0.7313, 0.0754, 0.5162, 0.5242],\n",
      "        [0.8571, 0.8887, 0.1337, 0.5136, 0.6388, 0.5130]])\n",
      "tensor([[0.9791, 0.4741],\n",
      "        [0.3318, 0.1018],\n",
      "        [0.3475, 0.8663],\n",
      "        [0.8571, 0.8887]])\n",
      "tensor([[0.6473, 0.5294],\n",
      "        [0.4189, 0.2183],\n",
      "        [0.7313, 0.0754],\n",
      "        [0.1337, 0.5136]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4,6)\n",
    "print(tensor)\n",
    "\n",
    "t1, t2, t3 = torch.chunk(tensor, 3, dim=1)\n",
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9517, 0.8751, 0.1557, 0.5818, 0.6179, 0.7744],\n",
      "        [0.9409, 0.5360, 0.0843, 0.2034, 0.2609, 0.3454],\n",
      "        [0.0107, 0.3365, 0.5918, 0.9065, 0.8989, 0.9607]])\n",
      "tensor([[0.9517, 0.8751, 0.1557],\n",
      "        [0.9409, 0.5360, 0.0843],\n",
      "        [0.0107, 0.3365, 0.5918]])\n",
      "tensor([[0.5818, 0.6179, 0.7744],\n",
      "        [0.2034, 0.2609, 0.3454],\n",
      "        [0.9065, 0.8989, 0.9607]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,6)\n",
    "t1, t2 = torch.split(tensor, 3, dim=1)\n",
    "print(tensor)\n",
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(7)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.ones(7)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AutoGrade (자동미분)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4390,  0.5501,  3.7345],\n",
      "        [-0.1464, -4.1999, -1.3505],\n",
      "        [-2.0067,  4.2650,  2.8033]])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3,3)\n",
    "a = a*3\n",
    "print(a)\n",
    "print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor(64.0028, grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x0000022EC0366FB0>\n"
     ]
    }
   ],
   "source": [
    "a.requires_grad_(True) \n",
    "print(a.requires_grad)\n",
    "\n",
    "b = (a*a).sum()\n",
    "print(b)\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient (기울기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3,3, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.],\n",
      "        [6., 6., 6.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x+5\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[36., 36., 36.],\n",
      "        [36., 36., 36.],\n",
      "        [36., 36., 36.]], grad_fn=<MulBackward0>) tensor(36., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n",
      "tensor([[1.3333, 1.3333, 1.3333],\n",
      "        [1.3333, 1.3333, 1.3333],\n",
      "        [1.3333, 1.3333, 1.3333]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-370.5100, 1433.3209, -609.0751], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x*2\n",
    "\n",
    "while y.data.norm() < 1000:\n",
    "    y = y*2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### with torch.no_grad() 를 사용하여 기울기의 업데이트를 하지 않음.\n",
    "\n",
    "- 기록을 추적하는 것을 방지하기 위해 코드 블럭을 **<span style=\"color:skyblue\">with torch.no_grad()로 감싸면 기울기 계산은 필요없지만, requires_grad=True로 설정되어 학습 가능한 매개변수를 갖는 모델을 평가(evaluate)할 때 유용함</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x**2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "y = x.detach()\n",
    "print(y.requires_grad)\n",
    "print(x.eq(y).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2,2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2,2, requires_grad=True)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(a.data)\n",
    "print(a.grad)\n",
    "print(a.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "b = a+2\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9.],\n",
      "        [9., 9.]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "c = b**2\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = c.sum()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[6., 6.],\n",
      "        [6., 6.]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(a.data)\n",
    "print(a.grad)\n",
    "print(a.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "None\n",
      "<AddBackward0 object at 0x0000022ED156F9D0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjong\\AppData\\Local\\Temp\\ipykernel_26716\\2485455394.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  print(b.grad)\n"
     ]
    }
   ],
   "source": [
    "print(b.data)\n",
    "print(b.grad)\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9.],\n",
      "        [9., 9.]])\n",
      "None\n",
      "<PowBackward0 object at 0x0000022ED156DBD0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjong\\AppData\\Local\\Temp\\ipykernel_26716\\3875808255.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  print(c.grad)\n"
     ]
    }
   ],
   "source": [
    "print(c.data)\n",
    "print(c.grad)\n",
    "print(c.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36.)\n",
      "None\n",
      "<SumBackward0 object at 0x0000022ED156F460>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjong\\AppData\\Local\\Temp\\ipykernel_26716\\578081240.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  print(out.grad)\n"
     ]
    }
   ],
   "source": [
    "print(out.data)\n",
    "print(out.grad)\n",
    "print(out.grad_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jjong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
